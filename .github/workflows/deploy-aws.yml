name: Deploy 4AMI Backend to AWS

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: 4ami-repo-backend
  ECS_SERVICE: 4ami-service
  ECS_CLUSTER: 4ami-cluster
  ECS_TASK_DEFINITION: 4ami-task
  CONTAINER_NAME: 4ami-container

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: package-lock.json

    - name: Install dependencies
      run: npm ci

    - name: Run linting
      run: npm run lint

    - name: Run tests
      run: npm run test

    - name: Build application
      run: npm run build

  deploy-infrastructure:
    name: Deploy AWS Infrastructure
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Generate unique suffix for resources
      id: unique_suffix_gen
      run: |
        UNIQUE_SUFFIX=$(head /dev/urandom | tr -dc a-z0-9 | head -c 8)
        echo "UNIQUE_SUFFIX=$UNIQUE_SUFFIX" >> $GITHUB_ENV
        echo "Generated unique suffix: $UNIQUE_SUFFIX"
      timeout-minutes: 1

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Verify AWS connection
      run: |
        echo "üîê Verifying AWS connection..."
        aws sts get-caller-identity
        echo "üåç AWS Region: $AWS_REGION"
        echo "‚úÖ AWS connection verified"
      timeout-minutes: 2

    - name: Check for existing resources
      run: |
        echo "üîç Checking for existing resources that might conflict..."
        echo "Checking VPCs..."
        aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ami-backend-vpc" --query 'Vpcs[].VpcId' --output text || echo "No existing VPCs found"
        echo "Checking RDS instances..."
        aws rds describe-db-instances --query 'DBInstances[?contains(DBInstanceIdentifier, `ami-backend`)].DBInstanceIdentifier' --output text || echo "No existing RDS instances found"
        echo "Checking ECR repositories..."
        aws ecr describe-repositories --repository-names ami-backend-repo --query 'repositories[].repositoryName' --output text || echo "No existing ECR repository found"
        echo "Checking IAM roles..."
        aws iam get-role --role-name ami-backend-ecs-execution-role --query 'Role.RoleName' --output text || echo "No existing execution role found"
        aws iam get-role --role-name ami-backend-ecs-task-role --query 'Role.RoleName' --output text || echo "No existing task role found"
        echo "Checking CloudWatch log groups..."
        aws logs describe-log-groups --log-group-name-prefix "/ecs/ami-backend" --query 'logGroups[].logGroupName' --output text || echo "No existing log groups found"
        echo "‚úÖ Resource check completed"
      timeout-minutes: 3

    - name: Clean up conflicting resources
      run: |
        echo "üßπ Cleaning up conflicting resources..."
        echo "Using unique suffix: ${{ env.UNIQUE_SUFFIX }}"
        
        # Delete ECR repository if it exists
        if aws ecr describe-repositories --repository-names ami-backend-${{ env.UNIQUE_SUFFIX }}-repo >/dev/null 2>&1; then
          echo "Deleting existing ECR repository..."
          aws ecr delete-repository --repository-name ami-backend-${{ env.UNIQUE_SUFFIX }}-repo --force
        fi
        
        # Delete CloudWatch log group if it exists
        if aws logs describe-log-groups --log-group-name-prefix "/ecs/ami-backend-${{ env.UNIQUE_SUFFIX }}" --query 'logGroups[].logGroupName' --output text | grep -q "/ecs/ami-backend-${{ env.UNIQUE_SUFFIX }}"; then
          echo "Deleting existing CloudWatch log group..."
          aws logs delete-log-group --log-group-name "/ecs/ami-backend-${{ env.UNIQUE_SUFFIX }}"
        fi
        
        # Delete IAM roles if they exist
        if aws iam get-role --role-name ami-backend-${{ env.UNIQUE_SUFFIX }}-ecs-execution-role >/dev/null 2>&1; then
          echo "Deleting existing ECS execution role..."
          aws iam detach-role-policy --role-name ami-backend-${{ env.UNIQUE_SUFFIX }}-ecs-execution-role --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy
          aws iam delete-role --role-name ami-backend-${{ env.UNIQUE_SUFFIX }}-ecs-execution-role
        fi
        
        if aws iam get-role --role-name ami-backend-${{ env.UNIQUE_SUFFIX }}-ecs-task-role >/dev/null 2>&1; then
          echo "Deleting existing ECS task role..."
          aws iam delete-role --role-name ami-backend-${{ env.UNIQUE_SUFFIX }}-ecs-task-role
        fi
        
        # Delete Load Balancer resources in correct order
        if aws elbv2 describe-load-balancers --names ami-backend-${{ env.UNIQUE_SUFFIX }}-alb --query 'LoadBalancers[].LoadBalancerName' --output text | grep -q "ami-backend-${{ env.UNIQUE_SUFFIX }}-alb"; then
          echo "Deleting existing Load Balancer and dependencies..."
          LB_ARN=$(aws elbv2 describe-load-balancers --names ami-backend-${{ env.UNIQUE_SUFFIX }}-alb --query 'LoadBalancers[0].LoadBalancerArn' --output text)
          
          # Delete listeners first
          LISTENERS=$(aws elbv2 describe-listeners --load-balancer-arn $LB_ARN --query 'Listeners[].ListenerArn' --output text)
          for listener in $LISTENERS; do
            echo "Deleting listener: $listener"
            aws elbv2 delete-listener --listener-arn $listener
          done
          
          # Wait a moment for listeners to be deleted
          sleep 10
          
          # Delete target groups
          TARGET_GROUPS=$(aws elbv2 describe-target-groups --load-balancer-arn $LB_ARN --query 'TargetGroups[].TargetGroupArn' --output text)
          for tg in $TARGET_GROUPS; do
            echo "Deleting target group: $tg"
            aws elbv2 delete-target-group --target-group-arn $tg
          done
          
          # Wait a moment for target groups to be deleted
          sleep 10
          
          # Finally delete the load balancer
          echo "Deleting load balancer: $LB_ARN"
          aws elbv2 delete-load-balancer --load-balancer-arn $LB_ARN
        fi
        
        # Delete RDS DB Subnet Group if it exists
        if aws rds describe-db-subnet-groups --db-subnet-group-name ami-backend-${{ env.UNIQUE_SUFFIX }}-db-subnet-group --query 'DBSubnetGroups[].DBSubnetGroupName' --output text | grep -q "ami-backend-${{ env.UNIQUE_SUFFIX }}-db-subnet-group"; then
          echo "Deleting existing RDS DB Subnet Group..."
          aws rds delete-db-subnet-group --db-subnet-group-name ami-backend-${{ env.UNIQUE_SUFFIX }}-db-subnet-group
        fi
        
        # Delete any remaining Target Groups
        TARGET_GROUPS=$(aws elbv2 describe-target-groups --query 'TargetGroups[?contains(TargetGroupName, `ami-backend-${{ env.UNIQUE_SUFFIX }}`)].TargetGroupArn' --output text)
        for tg in $TARGET_GROUPS; do
          echo "Deleting orphaned target group: $tg"
          aws elbv2 delete-target-group --target-group-arn $tg || echo "Target group $tg could not be deleted (may be in use)"
        done
        
        echo "‚úÖ Cleanup completed"
      timeout-minutes: 10

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: '1.6.0'

    - name: Terraform Init
      run: |
        echo "üöÄ Initializing Terraform..."
        terraform init -upgrade
        echo "‚úÖ Terraform initialized successfully"
      working-directory: aws-deployment/terraform
      timeout-minutes: 5

    - name: Terraform Validate
      run: |
        echo "üîç Validating Terraform configuration..."
        terraform validate
        echo "‚úÖ Terraform configuration is valid"
      working-directory: aws-deployment/terraform
      timeout-minutes: 2

    - name: Terraform Plan
      run: |
        echo "üìã Creating Terraform plan..."
        echo "üîç Running terraform plan with verbose output..."
        terraform plan -out=tfplan -detailed-exitcode \
          -var="db_password=${{ secrets.DB_PASSWORD || 'defaultpassword123' }}" \
          -var="jwt_secret=${{ secrets.JWT_SECRET || 'default-jwt-secret-key-12345' }}" \
          -var="mail_user=${{ secrets.MAIL_USER || 'noreply@4ami.com' }}" \
          -var="mail_pass=${{ secrets.MAIL_PASS || 'default-mail-password' }}" \
          -var="unique_suffix=${{ env.UNIQUE_SUFFIX }}" \
          -var="skip_final_snapshot=true" \
          -var="deletion_protection=false"
        echo "‚úÖ Terraform plan created successfully"
      working-directory: aws-deployment/terraform
      timeout-minutes: 10

    - name: Terraform Apply
      run: |
        echo "üèóÔ∏è Applying Terraform configuration..."
        terraform apply -auto-approve tfplan
        echo "‚úÖ Terraform applied successfully"
      working-directory: aws-deployment/terraform
      timeout-minutes: 25

  build-and-push:
    name: Build and Push Docker Image
    needs: [test, deploy-infrastructure]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2

    - name: Build, tag, and push image to Amazon ECR
      id: build-image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Build a docker container and push it to ECR
        docker build -f Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
        docker build -f Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY:latest .
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
        docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
        echo "image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_OUTPUT

  deploy:
    name: Deploy to AWS
    needs: [build-and-push, deploy-infrastructure]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Download task definition
      run: |
        aws ecs describe-task-definition --task-definition $ECS_TASK_DEFINITION --query taskDefinition > task-definition.json

    - name: Fill in the new image ID in the Amazon ECS task definition
      id: task-def
      uses: aws-actions/amazon-ecs-render-task-definition@v1
      with:
        task-definition: task-definition.json
        container-name: ${{ env.CONTAINER_NAME }}
        image: ${{ needs.build-and-push.outputs.image }}

    - name: Deploy Amazon ECS task definition
      uses: aws-actions/amazon-ecs-deploy-task-definition@v1
      with:
        task-definition: ${{ steps.task-def.outputs.task-definition }}
        service: ${{ env.ECS_SERVICE }}
        cluster: ${{ env.ECS_CLUSTER }}
        wait-for-service-stability: true

  test-deployment:
    name: Test Deployment
    needs: deploy
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Get Load Balancer DNS
      id: get-alb-dns
      run: |
        ALB_DNS=$(aws elbv2 describe-load-balancers --names 4ami-alb --query 'LoadBalancers[0].DNSName' --output text)
        echo "alb-dns=$ALB_DNS" >> $GITHUB_OUTPUT
        echo "API URL: https://$ALB_DNS/api/v1"

    - name: Wait for deployment to be ready
      run: |
        echo "Waiting for deployment to be ready..."
        sleep 60

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install Python dependencies
      run: |
        pip install requests

    - name: Run deployment tests
      run: |
        python aws-deployment/tests/test-backend-deployment.py --url https://${{ steps.get-alb-dns.outputs.alb-dns }}/api/v1

    - name: Setup Node.js for additional tests
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Run frontend-backend connection tests
      run: |
        node aws-deployment/tests/test-frontend-backend-connection.js https://${{ steps.get-alb-dns.outputs.alb-dns }}/api/v1

  notify:
    name: Notify Deployment Status
    needs: [deploy, test-deployment]
    runs-on: ubuntu-latest
    if: always() && github.ref == 'refs/heads/main'

    steps:
    - name: Notify Success
      if: needs.test-deployment.result == 'success'
      run: |
        echo "üéâ Deployment successful!"
        echo "Backend is now running on AWS"
        echo "Check the deployment in AWS Console"

    - name: Notify Failure
      if: needs.test-deployment.result == 'failure'
      run: |
        echo "‚ùå Deployment failed!"
        echo "Check the logs for more details"
        exit 1
